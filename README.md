# CHIRON: High-Fidelity Underwriting RAG

**Status:** Alpha (Ingestion Engine Active)  
**Core Philosophy:** The "Centaur" Architecture (Local Body / Cloud Brain)  
**Python:** 3.11+ | **Stack:** Docker, Postgres, Qdrant, LangGraph

---

## ğŸ›ï¸ Executive Summary

**Chiron** is a specialized Retrieval-Augmented Generation (RAG) engine designed for **Private Credit Underwriting**. Unlike generic chat bots, Chiron treats credit agreements, indentures, and financial models as structured databases, not unstructured text.

The system is engineered to solve the **"Trust Gap"** in financial AI by enforcing three non-negotiable standards:
1.  [cite_start]**Pixel-Perfect Grounding:** Every generated answer must point to verifiable coordinates (visual or native) in the source document[cite: 9, 52].
2.  **Audit-Ready Arithmetic:** The LLM is strictly forbidden from performing mental math. [cite_start]All calculations are executed via Python tools on extracted tabular data[cite: 400, 401].
3.  [cite_start]**Cost Discipline ("The Token Firewall"):** We maximize the use of local hardware (OCR, Layout Analysis, Embedding) to minimize API costs, sending only high-value reasoning tasks to the cloud[cite: 308, 309].

---

## ğŸ—ï¸ The "Centaur" Architecture

[cite_start]Chiron operates on a hybrid "Body/Brain" model to balance cost and precision[cite: 307].

### 1. The Dual-Helix Ingestion Pipeline
We reject the "one-size-fits-all" ingestion approach. [cite_start]Files are routed based on their semantic structure[cite: 450, 451].

```mermaid
graph TD
    User[User Upload] --> Router{Smart Router}
    
    %% Helix A: Visual Stream
    Router -- PDF / Scan --> Docling[Body: IBM Docling v2]
    Docling -->|Visual Layout| Layouts[Artifact: JSON Layouts]
    Docling -->|Clean Markdown| Text[Vector Indexing]
    
    %% Helix B: Native Stream
    Router -- XLSX / PPTX --> MarkItDown[Body: MarkItDown + OpenPyXL]
    MarkItDown -->|Logic Extraction| Tables[Artifact: Markdown Tables]
    MarkItDown --> Phantom[Body: Phantom Renderer]
    Phantom -->|Shadow PDF| ShadowCache[Visual: Rendered PDF]
    
    %% Convergence
    Layouts & Tables & ShadowCache --> Indexer[Indexer]
    Indexer --> Postgres[(Postgres: Lineage Ledger)]
    Indexer --> Blobs[(Local Blob Store)]
    Indexer --> Qdrant[(Qdrant: Vector Pointers)]
```

### 2. The Storage Layer: "The Three Truths"
[cite_start]To prevent "Metadata Bloat" in the Vector DB and ensure data integrity, Chiron decouples storage into three distinct layers[cite: 535, 562].

| Layer | Component | Role | Why? |
| :--- | :--- | :--- | :--- |
| **State Truth** | **PostgreSQL** (Docker) | **Lineage Ledger**. Tracks document status (Draft vs. Final), effective dates, and processing cost audit logs. | [cite_start]Prevents "Hallucinating Old Data" by filtering superseded drafts before retrieval[cite: 509, 511]. |
| **Content Truth** | **Local Blobs** (File System) | **Artifact Store**. Replaces Azure Blob Storage locally. Stores heavy `layouts/*.json` and `tables/*.md`. | Keeps the Vector DB lightweight. [cite_start]If the Vector Index is corrupted, it can be fully rebuilt from Blobs without re-ingesting[cite: 396]. |
| **Search Truth** | **Qdrant** (Docker) | **Pointer Index**. Stores embeddings and `chunk_id` references only. | [cite_start]Optimized for speed and semantic retrieval, not data storage[cite: 538]. |

### 3. The Reasoning Engine (Lexical Graph)
[cite_start]We utilize a **Lexical Graph** approach rather than "Semantic Hops" to solve the specific complexity of Credit Agreements[cite: 403, 426].

* **Term Injection:** A Regex-driven pass extracts "Article I: Definitions" during ingestion. [cite_start]These are stored as artifacts and injected into the LLM context *only* when the defined term is detected in the query[cite: 408, 411].
* [cite_start]**The Phantom DOM:** For native files (Excel), the system cites a "Shadow PDF" generated by Playwright, allowing the frontend to render "pixel-perfect" highlights even for spreadsheet cells[cite: 466, 467].

---

## ğŸ“‚ Directory Structure & Design Intent

[cite_start]This structure is designed to facilitate a seamless migration to Azure[cite: 323].

```text
chiron/
â”œâ”€â”€ data/                       # [SINGLE SOURCE OF TRUTH]
â”‚   â”œâ”€â”€ inputs/                 # Drop zone for raw PDFs/Excel
â”‚   â”œâ”€â”€ system/                 # The State Truth (Dev mode hook)
â”‚   â”œâ”€â”€ blobs/                  # The Content Truth (Simulates Azure Blob Container)
â”‚   â”‚   â”œâ”€â”€ layouts/            # JSON Coordinate Maps
â”‚   â”‚   â””â”€â”€ tables/             # Full Markdown Tables
â”‚   â””â”€â”€ shadow_cache/           # The Visual Truth (Phantom PDFs)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py               # Factory Pattern: Toggles OpenAI (Dev) <-> Azure (Prod)
â”‚   â”œâ”€â”€ ingestion/              # [LOCAL BODY] The Dual-Helix Engine
â”‚   â”‚   â”œâ”€â”€ filters.py          # Token Firewall logic
â”‚   â”‚   â”œâ”€â”€ native_parser.py    # MarkItDown + OpenPyXL fallback
â”‚   â”‚   â”œâ”€â”€ pdf_parser.py       # Docling v2 with Visual Context Injection
â”‚   â”‚   â”œâ”€â”€ phantom.py          # Playwright "Shadow PDF" generator
â”‚   â”‚   â”œâ”€â”€ pipeline.py         # The Orchestrator
â”‚   â”‚   â””â”€â”€ router.py           # Smart routing (Visual vs Native)
â”‚   â”œâ”€â”€ retrieval/              # [SEARCH TRUTH - READ]
â”‚   â”‚   â”œâ”€â”€ qdrant.py           # Search Logic (The "Brain" uses this)
â”‚   â”‚   â”œâ”€â”€ sidecar.py          # Context Window Manager
â”‚   â”‚   â””â”€â”€ term_injector.py    # Regex Definitions Extractor
â”‚   â”œâ”€â”€ schemas/                # [TYPE SAFETY] Shared Pydantic Models
â”‚   â”‚   â”œâ”€â”€ citation.py         # "Pixel-Perfect" citation object
â”‚   â”‚   â”œâ”€â”€ documents.py        # Chunk definitions
â”‚   â”‚   â””â”€â”€ state.py            # LangGraph state schema
â”‚   â”œâ”€â”€ storage/                # [THE THREE TRUTHS - WRITE]
â”‚   â”‚   â”œâ”€â”€ blob_driver.py      # Content Truth (Writes to blobs/)
â”‚   â”‚   â”œâ”€â”€ db_driver.py        # State Truth (Writes to Postgres)
â”‚   â”‚   â””â”€â”€ vector_driver.py    # Search Truth (Writes to Qdrant)
â”‚   â”œâ”€â”€ tools/                  # [AGENT TOOLS]
â”‚   â”‚   â”œâ”€â”€ calculator.py       # Python Math Engine
â”‚   â”‚   â”œâ”€â”€ database.py         # SQL Lookup Tool
â”‚   â”‚   â””â”€â”€ vision.py           # GPT-4o Visual Analysis Tool
â”‚   â”œâ”€â”€ utils/                  # [OBSERVABILITY]
â”‚   â”‚   â”œâ”€â”€ resilience.py       # Retry decorators & JSON repair
â”‚   â”‚   â”œâ”€â”€ telemetry.py        # Cost tracking
â”‚   â”‚   â””â”€â”€ tracing.py          # LangSmith connection
â”‚   â””â”€â”€ workflows/              # [CLOUD BRAIN] LangGraph Logic
â”‚       â”œâ”€â”€ graph.py            # The State Machine Controller
â”‚       â”œâ”€â”€ router.py           # Semantic Intent Router
â”‚       â””â”€â”€ nodes/              # Discrete Reasoning Steps
â”‚           â”œâ”€â”€ financial_math.py
â”‚           â””â”€â”€ legal_reasoning.py
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ benchmarks/
â”‚   â”‚   â””â”€â”€ cost_analysis.py
â”‚   â””â”€â”€ units/
â”œâ”€â”€ .env
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ run_ingestion.py            # [TRIGGER] Manual entry point
```
---

## ğŸ›¡ï¸ Developer Guidelines (Strict Enforcement)

### 1. The "Token Firewall"
* **Rule:** Never send raw chunks to the LLM without stripping visual noise.
* **Implementation:** All chunks must be cleaned of headers, footers, and decorative artifacts locally before embedding.

### 2. Auditability & Citations
* **Rule:** Every answer must return a `Citation` object.
* **Implementation:** Use the `src.schemas.citation.Citation` Pydantic model. If the source is native (Excel), use the `native_id` (Cell ID) and map it to the `shadow_cache` for visualization.

### 3. No Mental Math
* **Rule:** If the user asks for a calculation (e.g., "Leverage Ratio"), the Agent **MUST** use the `calculator` tool.
* **Implementation:** The agent must load the full table from `data/blobs/tables/` into a Pandas DataFrame and execute the logic in Python.

### 4. Defensive Coding
* **Rule:** Assume parsers will fail.
* **Implementation:** In `native_parser.py`, if `markitdown` fails or returns empty text, explicitly catch the error and fall back to `openpyxl` raw extraction.

---

## ğŸš€ Quick Start

1.  **Initialize Infrastructure:**
    ```bash
    docker compose up -d  # Spins up Postgres & Qdrant
    ```

2.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    playwright install chromium
    ```

3.  **Environment Setup:**
    Configure `.env` with `DEPLOYMENT_MODE="OPENAI_DEV"` and your `OPENAI_API_KEY`.

4. **Run Ingestion:**
    Place PDFs or Excel files in `data/inputs/` and run:
    ```bash
    python run_ingestion.py
    ```
    *This will parse the files, generate shadow artifacts, and register them in the Postgres Ledger.*